{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNgSqlhgj83wMhw7xtLwlB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHUBHAMGAWADE7798/NLP-Programs/blob/main/Multi_Task_NLP_Toolkit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuW-i660VABT",
        "outputId": "a69945fc-c141-4c25-8db6-ed94805eead1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the text: hey hi my sunshine\n",
            "Choose a task to perform:\n",
            "1. Text Generation\n",
            "2. Summarization\n",
            "3. Sentiment Analysis\n",
            "4. Exit\n",
            "Enter your choice (1-4): 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Text Generation ===\n",
            "hey hi my sunshine. I'm a little shy, but hey. I'm very pretty. What do you say? I said hello to you, thank you. Thank you, thank you. Oh, hello. I'd like to introduce you to my new boyfriend, who is a real gregarious, fun-loving guy. He will be a big fan of mine, and I'm sure he'll like it when I show him what I'm doing. How do you like him? He likes to make friends. He likes to play video games with me. He likes to watch me play. I'll be his girlfriend for a while, but by then, he'll be a big fan too. Good luck. Bye bye.\"\n",
            "\n",
            "\"Ah-huh, I think I'm done, thank you,\" she said, shaking her head.\n",
            "\n",
            "\"No worries, good night. Now, my name's M.A.M., and I'm a photographer, so I'm going to be using my camera to photograph things around here,\" she said.\n",
            "\n",
            "She smiled, then took a few deep breaths. \"I'm glad you're up, I hope you're alright.\"\n",
            "Enter your choice (1-4): 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 50, but your input_length is only 6. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Text Summarization ===\n",
            "Hey hi my sunshine. Hey hi my Sunshine. hey hi my sunny day. heyHi my sunshine! HeyHiMySunshine. HeyHi my Sunshine!\n",
            "Enter your choice (1-4): 3\n",
            "=== Sentiment Analysis ===\n",
            "Label: POSITIVE, Score: 0.9996\n",
            "Enter your choice (1-4): 4\n",
            "Exiting...Bye!\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "text_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "input_text = input(\"Enter the text: \")\n",
        "\n",
        "print(\"Choose a task to perform:\")\n",
        "print(\"1. Text Generation\")\n",
        "print(\"2. Summarization\")\n",
        "print(\"3. Sentiment Analysis\")\n",
        "print(\"4. Exit\")\n",
        "\n",
        "while True:\n",
        "    choice = input(\"Enter your choice (1-4): \")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        generated_text = text_generator(input_text, max_length=50, num_return_sequences=1)\n",
        "        print(\"=== Text Generation ===\")\n",
        "        print(generated_text[0]['generated_text'])\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        summary = summarizer(input_text, max_length=50, min_length=25, do_sample=False)\n",
        "        print(\"=== Text Summarization ===\")\n",
        "        print(summary[0]['summary_text'])\n",
        "\n",
        "    elif choice == \"3\":\n",
        "        sentiment = sentiment_analyzer(input_text)\n",
        "        print(\"=== Sentiment Analysis ===\")\n",
        "        print(f\"Label: {sentiment[0]['label']}, Score: {sentiment[0]['score']:.4f}\")\n",
        "\n",
        "    elif choice == \"4\":\n",
        "        print(\"Exiting...Bye!\")\n",
        "        break\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid choice. Please try again.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-lT0vFQYbD2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}